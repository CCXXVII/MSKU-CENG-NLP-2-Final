{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iC32tMWtb1E",
        "outputId": "d85d10a2-e0c2-4765-8fd6-9b3314adc334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bQGJupeyykV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('drive/MyDrive/teknofest.csv', delimiter='|')\n",
        "\n",
        "#TWEET ÖN İŞLEME\n",
        "import re\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    # Remove non-alphanumeric characters (including numbers) and convert to lowercase\n",
        "    tweet = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', '', tweet.lower())\n",
        "    \n",
        "    # Tokenize tweet\n",
        "    tokens = tweet.split()\n",
        "    \n",
        "    # Take first 5 letters of each word\n",
        "    tokens = [word[:5] for word in tokens]\n",
        "    \n",
        "    # Join tokens back into a string\n",
        "    clean_tweet = ' '.join(tokens)\n",
        "    \n",
        "    return clean_tweet\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: clean_tweet(x))\n",
        "\n",
        "#DATAYI BALANCE HALE GETİRMEK İÇİN TRAİN_DF ÜZERİNDEN SINIFLARA BÖLME\n",
        "train_df = df.copy()\n",
        "from sklearn.utils import resample\n",
        "minority_class = train_df[train_df.is_offensive == 0]#OFENSİF OLMAYANLAR\n",
        "insult_class = train_df[train_df.target == 'INSULT']#DİĞEr DÖRT SINIF\n",
        "racist_class = train_df[train_df.target == 'RACIST']\n",
        "sexist_class = train_df[train_df.target == 'SEXIST']\n",
        "profanity_class = train_df[train_df.target == 'PROFANITY']\n",
        "\n",
        "#HER SINIFTAN (NEGATİF TWEETLER İÇİN) 900 VERİ ALMA + POZİTİF TWEETLER\n",
        "\n",
        "n_samples = 900\n",
        "insult_class_resampled = resample(insult_class, replace=False, n_samples=n_samples, random_state=42)\n",
        "racist_class_resampled = resample(racist_class, replace=False, n_samples=n_samples, random_state=42)\n",
        "sexist_class_resampled = resample(sexist_class, replace=False, n_samples=n_samples, random_state=42)\n",
        "profanity_class_resampled = resample(profanity_class, replace=False, n_samples=n_samples, random_state=42)\n",
        "\n",
        "#NAİVE BAYES MODELİ İÇİN BALANCE DATAFRAME OLUŞTURMA\n",
        "offensive_df = pd.concat([minority_class, insult_class_resampled,racist_class_resampled,sexist_class_resampled,profanity_class_resampled])\n",
        "\n",
        "#BERT İÇİN SADECE NEGATİF VERİLER İLE DATAFRAME OLUŞTURMA\n",
        "negative_df = train_df[train_df['target'] != 'OTHER']\n",
        "\n",
        "#VERİLERİ SHUFFLE İLE KARIŞTIRIYORUZ\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "offensive_df = shuffle(offensive_df, random_state=42)\n",
        "negative_df = shuffle(negative_df, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqbninH4y4St"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes MODELİ TRAİN KISMI\n",
        "\n",
        "X_train = offensive_df['text']\n",
        "y_train = offensive_df['is_offensive']\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#NB MODELİNİ KAYDETME\n",
        "import pickle\n",
        "with open('nb_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXig7Vr3y9Vp"
      },
      "outputs": [],
      "source": [
        "#NEGATİF TWEETLERİ BERT MODELİNE UYGUN HALE GETİRME\n",
        "import pandas as pd\n",
        "\n",
        "target_mapping = {\"INSULT\": 1, \"RACIST\": 2, \"SEXIST\": 3, \"PROFANITY\": 4}\n",
        "negative_df[\"target\"] = negative_df[\"target\"].map(target_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5VhMyX6zAFp",
        "outputId": "0abc72c6-0df1-4e64-fcc7-8b37e58e33ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHwpPFObzKfb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "import torch\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer= AutoTokenizer.from_pretrained(\"savasy/bert-turkish-text-classification\")\n",
        "model= AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-turkish-text-classification\")\n",
        "\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "train_encodings = tokenizer(list(negative_df['text']), truncation=True, padding=True)\n",
        "train_labels = np.array(list(negative_df['target']))\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(train_encodings['input_ids']),\n",
        "    torch.tensor(train_encodings['attention_mask']),\n",
        "    torch.tensor(train_labels))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_mask, labels = tuple(t.to(device) for t in batch)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "#BERT MODELİNİ KAYDETME\n",
        "\n",
        "with open('bert_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hxc6WJLtX3_",
        "outputId": "3ef5fbd0-ce82-4544-da26-d620a9646cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.24.1-py3-none-any.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from gradio) (1.22.4)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson\n",
            "  Downloading orjson-3.8.9-cp39-cp39-manylinux_2_28_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.1/144.1 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from gradio) (1.4.4)\n",
            "Collecting semantic-version\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from gradio) (1.10.7)\n",
            "Collecting gradio-client>=0.0.5\n",
            "  Downloading gradio_client-0.0.8-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from gradio) (4.5.0)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-11.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from gradio) (2.27.1)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from gradio) (4.2.2)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting mdit-py-plugins<=0.3.3\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.9/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.9/dist-packages (from gradio) (0.13.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from gradio) (6.0)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from gradio) (3.1.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from gradio-client>=0.0.5->gradio) (23.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from gradio-client>=0.0.5->gradio) (2023.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.10.7)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1\n",
            "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Collecting starlette<0.27.0,>=0.26.1\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->gradio) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn->gradio) (8.1.3)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.15.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4707 sha256=0518bde7bee1ae36b61c6f0763cd8af5a7046005996d9d8faa2a9eda352f2d99\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: rfc3986, pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, httpcore, aiosignal, httpx, gradio-client, fastapi, aiohttp, gradio\n",
            "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 fastapi-0.95.0 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.24.1 gradio-client-0.0.8 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 linkify-it-py-2.0.0 mdit-py-plugins-0.3.3 multidict-6.0.4 orjson-3.8.9 pydub-0.25.1 python-multipart-0.0.6 rfc3986-1.5.0 semantic-version-2.10.0 starlette-0.26.1 uc-micro-py-1.0.1 uvicorn-0.21.1 websockets-11.0.1 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvegHeIc_oWn"
      },
      "outputs": [],
      "source": [
        "\n",
        "#ÖNİŞLEME FONKSİYONU TEST VERİSİ İÇİN\n",
        "def preprocess_tweet(tweet):\n",
        "    # Remove non-alphanumeric characters (including numbers) and convert to lowercase\n",
        "    tweet = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', '', tweet.lower())\n",
        "    # Tokenize tweet\n",
        "    tokens = tweet.split()\n",
        "    # Take first 5 letters of each word\n",
        "    tokens = [word[:5] for word in tokens]\n",
        "    # Join tokens back into a string\n",
        "    clean_tweet = ' '.join(tokens)\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzigeDb4AHdA"
      },
      "outputs": [],
      "source": [
        "pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJW1BkbjtVCd",
        "outputId": "1fe2ad87-9b85-4cf4-a03d-fc04783913f2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://f9787f780f8ea88163.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/routes.py\", line 393, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 1108, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 915, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-9-ad5a85b04d75>\", line 49, in predict\n",
            "    df=df.drop(['offansive'],axis=1)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\", line 4957, in drop\n",
            "    return super().drop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4267, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4311, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\", line 6661, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['offansive'] not found in axis\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/routes.py\", line 393, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 1108, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 915, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-9-ad5a85b04d75>\", line 49, in predict\n",
            "    df=df.drop(['offansive'],axis=1)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\", line 4957, in drop\n",
            "    return super().drop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4267, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4311, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\", line 6661, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['offansive'] not found in axis\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/routes.py\", line 393, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 1108, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 915, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-9-ad5a85b04d75>\", line 49, in predict\n",
            "    df=df.drop(['offansive'],axis=1)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\", line 4957, in drop\n",
            "    return super().drop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4267, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4311, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\", line 6661, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['offansive'] not found in axis\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/routes.py\", line 393, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 1108, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 915, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-9-ad5a85b04d75>\", line 49, in predict\n",
            "    df=df.drop(['offansive'],axis=1)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\", line 4957, in drop\n",
            "    return super().drop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4267, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4311, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\", line 6661, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['offansive'] not found in axis\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/routes.py\", line 393, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 1108, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 915, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-9-ad5a85b04d75>\", line 49, in predict\n",
            "    df=df.drop(['offansive'],axis=1)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\", line 4957, in drop\n",
            "    return super().drop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4267, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4311, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\", line 6661, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['offansive'] not found in axis\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/routes.py\", line 393, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 1108, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 915, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-9-ad5a85b04d75>\", line 49, in predict\n",
            "    df=df.drop(['offansive'],axis=1)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\", line 4957, in drop\n",
            "    return super().drop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4267, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4311, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\", line 6661, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['offansive'] not found in axis\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/routes.py\", line 393, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 1108, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 915, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-9-ad5a85b04d75>\", line 49, in predict\n",
            "    df=df.drop(['offansive'],axis=1)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\", line 4957, in drop\n",
            "    return super().drop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4267, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4311, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\", line 6661, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['offansive'] not found in axis\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/routes.py\", line 393, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 1108, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/gradio/blocks.py\", line 915, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-9-ad5a85b04d75>\", line 49, in predict\n",
            "    df=df.drop(['offansive'],axis=1)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\", line 4957, in drop\n",
            "    return super().drop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4267, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 4311, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\", line 6661, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['offansive'] not found in axis\"\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def auth(username, password):\n",
        "    if username == \"MSKU-CENG-NLP-2\" and password == \"JMTU7FVNKFKFKW4J\":\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "#ÖNİŞLEME FONKSİYONU TEST VERİSİ İÇİN\n",
        "def preprocess_tweet(tweet):\n",
        "    # Remove non-alphanumeric characters (including numbers) and convert to lowercase\n",
        "    tweet = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', '', tweet.lower())\n",
        "    # Tokenize tweet\n",
        "    tokens = tweet.split()\n",
        "    # Take first 5 letters of each word\n",
        "    tokens = [word[:5] for word in tokens]\n",
        "    # Join tokens back into a string\n",
        "    clean_tweet = ' '.join(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def predict(df):\n",
        "    output_file = \"output_MSKU-CENG-NLP-2.csv\"\n",
        "\n",
        "    df = pd.read_csv(df.name, sep=\"|\")\n",
        "    df[\"offansive\"] = None\n",
        "    df[\"target\"] = None\n",
        "    #ÖNİŞLEMENİN TEST VERİSETİNE UYGULANMASI\n",
        "    df=df.drop(['offansive'],axis=1)\n",
        "    df=df.drop(['target'],axis=1)\n",
        "    df['text'] = df['text'].apply(preprocess_tweet)\n",
        "    \n",
        "    #KAYDEDİLEN MODELLERİN YÜKLENMESİ\n",
        "    with open('nb_model.pkl', 'rb') as f:\n",
        "      nb_loaded_model = pickle.load(f)\n",
        "\n",
        "    with open('bert_model.pkl', 'rb') as f:\n",
        "      bert_loaded_model = pickle.load(f)\n",
        "\n",
        "    #NB PREDİCTİON\n",
        "    X_test = df['text']\n",
        "\n",
        "\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "\n",
        "    nb_pred = nb_loaded_model.predict(X_test)\n",
        "    df['offansive'] = nb_pred\n",
        "       \n",
        "    #BERTE SOKULACAK NEGATİF ETİKETLİ TWEETLER İÇİN YENİ DATAFRAME OLUŞTURMA\n",
        "    neg_results = df[df['offansive'] == 1]\n",
        "    \n",
        "    #BERT TEST\n",
        "    bert_loaded_model.eval()\n",
        "    test_encodings = tokenizer(list(neg_results['text']), truncation=True, padding=True)\n",
        "    test_dataset = torch.utils.data.TensorDataset(\n",
        "        torch.tensor(test_encodings['input_ids']),\n",
        "        torch.tensor(test_encodings['attention_mask']))\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=16,\n",
        "        shuffle=False)\n",
        "\n",
        "    # TEST DATA İLE PREDİCTİON\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids, attention_mask = tuple(t.to(device) for t in batch)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predictions.extend(torch.argmax(logits, axis=1).tolist())\n",
        "\n",
        "    neg_results['target'] = predictions\n",
        "  \n",
        "    #VERİLEN DF İLE NEGATİF ETİKETLİ TWEETLERİN 4 SINIF TAHMİNLERİNİ BİRLEŞTİRME\n",
        "    df = pd.merge(df, neg_results[['id', 'target']], on='id', how='left')\n",
        "\n",
        "    #TARGET COLUMNDAKİ BOŞLUKLARI OTHER İLE DOLDURMA\n",
        "    df['target'] = df['target'].fillna('OTHER')\n",
        "\n",
        "    #UYGUN ÇIKTI İÇİN TARGET MAP UYGULAMASI\n",
        "    target_mapping = {1: \"INSULT\", 2: \"RACIST\", 3: \"SEXIST\", 4: \"PROFANITY\", 'OTHER' : 'OTHER'}\n",
        "    df[\"target\"] = df[\"target\"].map(target_mapping)\n",
        "\n",
        "    #TAHMİNLERİ CSV HALİNE GETİRME\n",
        "    df.to_csv(output_file, index=False, sep=\"|\")\n",
        "    return (output_file)\n",
        "\n",
        "iface = gr.Interface(predict, \"file\", \"file\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch(share=True, auth=auth,debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeN5bhCeBV2E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}